{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LassoCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat1 = pd.read_csv('policy_0702.csv',encoding='UTF-8')\n",
    "dat2 = pd.read_csv('claim_0702.csv',encoding='UTF-8')\n",
    "dat3 = pd.read_csv('training-set.csv',encoding='UTF-8')\n",
    "dat4 = pd.read_csv('testing-set.csv',encoding='UTF-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 資料處理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat1['Cancellation'] = dat1['Cancellation'].apply({'Y':1, ' ':0}.get)\n",
    "dat1['Main_Insurance_Coverage_Group'] = dat1['Main_Insurance_Coverage_Group'].apply({'車責':0, '竊盜':1, '車損':2}.get)\n",
    "dat1['ibirth'] = dat1['ibirth'].str[3:7].astype('float') + (dat1['ibirth'].str[0:2].astype('float')-1)/12\n",
    "dat1['ibirth'] = dat1['ibirth'].fillna(dat1['ibirth'].mean())\n",
    "dat1['dbirth'] = dat1['dbirth'].str[3:7].astype('float') + (dat1['dbirth'].str[0:2].astype('float')-1)/12\n",
    "dat1['dbirth'] = dat1['dbirth'].fillna(dat1['dbirth'].mean())\n",
    "dat1['nequipment9'] = dat1['nequipment9'].apply({    '                                                                                                    ':1,\n",
    "    ' ':1,    '原裝車含配備':2,'5合1影音':3,'大包':4,\n",
    "    '伸尾                                                                                                ':5}.get)\n",
    "dat1.fsex = dat1.fsex.apply({'1':1,'2':2,' ':0}.get).fillna(0)\n",
    "dat1.fmarriage = dat1.fmarriage.apply({'1':1,'2':2,' ':0}.get).fillna(0)\n",
    "\n",
    "# 單一保單個數\n",
    "dat1['Policy_counts'] = dat1['Policy_Number'].map(dat1['Policy_Number'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat1['Main_Insurance_Coverage_Group'] = dat1['Main_Insurance_Coverage_Group'].astype('category')\n",
    "dat1['Insurance_Coverage'] = dat1['Insurance_Coverage'].astype('category')\n",
    "dat1['Cancellation'] = dat1['Cancellation'].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dat1[13:19] 要特殊處理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = dat1.groupby(by ='Policy_Number',axis=0,sort=False).Main_Insurance_Coverage_Group.\\\n",
    "value_counts().reset_index(name='Main_Insurance_count')\n",
    "a1 = a1.pivot_table(index='Policy_Number', columns='Main_Insurance_Coverage_Group', \\\n",
    "                    values='Main_Insurance_count',fill_value=0)\n",
    "a2 = dat1.pivot_table(index=['Policy_Number'],columns='Main_Insurance_Coverage_Group',values=['Insured_Amount1', \n",
    "               'Insured_Amount2', 'Insured_Amount3','Coverage_Deductible_if_applied'],fill_value=0)\n",
    "a3 = dat1.groupby(by ='Policy_Number',axis=0,sort=False).Insurance_Coverage.value_counts().reset_index(name='Insurance_Coverage_count')\n",
    "a3 = a3.pivot_table(index='Policy_Number', columns='Insurance_Coverage', values='Insurance_Coverage_count',fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 補缺失值\n",
    "dat1.Vehicle_identifier = dat1.Vehicle_identifier.fillna(dat1.Policy_Number)\n",
    "dat1.Prior_Policy_Number = dat1.Prior_Policy_Number.fillna('0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], dtype: int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat1.count()[dat1.count()<1747942]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 將 Insured's_ID 轉數字\n",
    "dat1[\"Insured's_ID\"] = pd.Categorical(dat1[\"Insured's_ID\"])\n",
    "dat1[\"Insured's_ID\"] = dat1[\"Insured's_ID\"].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dat1.Vehicle_identifier = pd.Categorical(dat1.Vehicle_identifier)\n",
    "dat1.Vehicle_identifier = dat1.Vehicle_identifier.cat.codes\n",
    "dat1.Vehicle_Make_and_Model1 = pd.Categorical(dat1.Vehicle_Make_and_Model1)\n",
    "dat1.Vehicle_Make_and_Model1 = dat1.Vehicle_Make_and_Model1.cat.codes\n",
    "dat1.Vehicle_Make_and_Model2 = pd.Categorical(dat1.Vehicle_Make_and_Model2)\n",
    "dat1.Vehicle_Make_and_Model2 = dat1.Vehicle_Make_and_Model2.cat.codes\n",
    "dat1.Distribution_Channel = pd.Categorical(dat1.Distribution_Channel)\n",
    "dat1.Distribution_Channel = dat1.Distribution_Channel.cat.codes\n",
    "dat1.aassured_zip = pd.Categorical(dat1.aassured_zip)\n",
    "dat1.aassured_zip = dat1.aassured_zip.cat.codes\n",
    "dat1.iply_area = pd.Categorical(dat1.iply_area)\n",
    "dat1.iply_area = dat1.iply_area.cat.codes\n",
    "dat1.Prior_Policy_Number = pd.Categorical(dat1.Prior_Policy_Number)\n",
    "dat1.Prior_Policy_Number = dat1.Prior_Policy_Number.cat.codes\n",
    "dat1[\"Coding_of_Vehicle_Branding_&_Type\"] = pd.Categorical(dat1[\"Coding_of_Vehicle_Branding_&_Type\"])\n",
    "dat1[\"Coding_of_Vehicle_Branding_&_Type\"] = dat1[\"Coding_of_Vehicle_Branding_&_Type\"].cat.codes\n",
    "dat1.ibirth = dat1.ibirth.astype('float')\n",
    "dat1.dbirth = dat1.dbirth.astype('float')\n",
    "del dat1['fpt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Policy_Number    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat1.dtypes[dat1.dtypes=='object']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yifor\\Anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:543: UserWarning: merging between different levels can give an unintended result (1 levels on the left, 2 on the right)\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "dat = dat1[list(dat1.columns[0:12]) +list(dat1.columns[20:43]) ].drop_duplicates().reset_index(drop=True)\n",
    "dat['Premium'] = dat1.groupby('Policy_Number',sort=False)['Premium'].sum().values\n",
    "dat = pd.merge(dat, a1, on=['Policy_Number'], how='left')\n",
    "dat = pd.merge(dat, a2, on=['Policy_Number'], how='left')\n",
    "dat = pd.merge(dat, a3, on=['Policy_Number'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], dtype: int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat.isnull().sum()[dat.isnull().sum()>0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 處理dat2資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "a4 = dat2[['Policy_Number','Claim_Number']].drop_duplicates().reset_index(drop=True)\n",
    "a4['acc_count'] = 1\n",
    "dat2['acc_count'] = dat2['Policy_Number'].map(a4.groupby('Policy_Number',sort=False)['acc_count'].sum())\n",
    "\n",
    "dat2['DOB_of_Driver'] = dat2['DOB_of_Driver'].str[3:7].astype('float') + (dat2['DOB_of_Driver'].str[0:2].astype('float')-1)/12\n",
    "dat2['DOB_of_Driver'] = dat2['DOB_of_Driver'].fillna(dat2['DOB_of_Driver'].mean())\n",
    "\n",
    "dat2['Accident_Time'] = dat2['Accident_Time'].str[0:2].astype('float')*60 + dat2['Accident_Time'].str[3:5].astype('float')\n",
    "dat2[\"At_Fault?\"] = dat2[\"At_Fault?\"].fillna(dat2[\"At_Fault?\"].mean()  )\n",
    "dat2['Vehicle_identifier'] = dat2['Vehicle_identifier'].fillna(dat2['Policy_Number']  )\n",
    "dat2.Accident_Date = (dat2.Accident_Date.str[0:4].astype('float'))+( dat2.Accident_Date.str[5:7].astype('float')-1)/12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dat2[\"Cause_of_Loss\"] = pd.Categorical(dat2[\"Cause_of_Loss\"])\n",
    "dat2[\"Cause_of_Loss\"] = dat2[\"Cause_of_Loss\"].cat.codes\n",
    "\n",
    "dat2[\"Vehicle_identifier\"] = pd.Categorical(dat2[\"Vehicle_identifier\"])\n",
    "dat2[\"Vehicle_identifier\"] = dat2[\"Vehicle_identifier\"].cat.codes\n",
    "\n",
    "dat2[\"Accident_area\"] = pd.Categorical(dat2[\"Accident_area\"])\n",
    "dat2[\"Accident_area\"] = dat2[\"Accident_area\"].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], dtype: int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat2.isnull().sum()[dat2.isnull().sum()>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a5 = dat2.groupby(by ='Policy_Number',axis=0,sort=False).Coverage.value_counts().reset_index(name='Coverage_count')\n",
    "a5 = a5.pivot_table(index='Policy_Number', columns='Coverage', values='Coverage_count',fill_value=0)\n",
    "dat = pd.merge(dat, a5, on=['Policy_Number'], how='left',sort=False).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#dat2.columns\n",
    "dat2['Nature_of_the_claim'] = dat2['Nature_of_the_claim'].astype('category')\n",
    "dat2[\"Driver's_Gender\"] = dat2[\"Driver's_Gender\"].astype('category')\n",
    "dat2[\"Driver's_Relationship_with_Insured\"] = dat2[\"Driver's_Relationship_with_Insured\"].astype('category')\n",
    "dat2['Marital_Status_of_Driver'] = dat2['Marital_Status_of_Driver'].astype('category')\n",
    "dat2['Claim_Status_(close,_open,_reopen_etc)'] = dat2['Claim_Status_(close,_open,_reopen_etc)'].astype('category')\n",
    "dat2['Accident_area'] = dat2['Accident_area'].astype('category')\n",
    "del dat2['Vehicle_identifier'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Claim_Number                                object\n",
       "Nature_of_the_claim                       category\n",
       "Policy_Number                               object\n",
       "Driver's_Gender                           category\n",
       "Driver's_Relationship_with_Insured        category\n",
       "DOB_of_Driver                              float64\n",
       "Marital_Status_of_Driver                  category\n",
       "Accident_Date                              float64\n",
       "Cause_of_Loss                                 int8\n",
       "Paid_Loss_Amount                             int64\n",
       "paid_Expenses_Amount                         int64\n",
       "Salvage_or_Subrogation?                      int64\n",
       "Coverage                                    object\n",
       "At_Fault?                                  float64\n",
       "Claim_Status_(close,_open,_reopen_etc)    category\n",
       "Deductible                                   int64\n",
       "Accident_area                             category\n",
       "number_of_claimants                        float64\n",
       "Accident_Time                              float64\n",
       "acc_count                                    int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat2.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df2 = dat2[['Policy_Number','Claim_Number',\"Driver's_Gender\",'DOB_of_Driver','Marital_Status_of_Driver',\\\n",
    "     'Accident_Date','Cause_of_Loss','Accident_area','number_of_claimants',\\\n",
    "            'Accident_Time',\"At_Fault?\"]].drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nature_of_the_claim\n",
    "a6 = dat2.groupby('Policy_Number',sort=False)['Nature_of_the_claim'].value_counts().reset_index(name='Nature_of_the_claim_count')\n",
    "a6 = a6.pivot_table(index='Policy_Number', columns='Nature_of_the_claim',values='Nature_of_the_claim_count',fill_value=0)\n",
    "\n",
    "# Marital_Status_of_Driver\n",
    "a7 = df2.groupby('Policy_Number',sort=False)['Marital_Status_of_Driver'].value_counts().reset_index(name='Marital_Status_of_Driver_count')\n",
    "a7 = a7.pivot_table(index='Policy_Number', columns='Marital_Status_of_Driver',values='Marital_Status_of_Driver_count',fill_value=0)\n",
    "\n",
    "# Driver's_Gender\n",
    "a8 = df2.groupby('Policy_Number',sort=False)[\"Driver's_Gender\"].value_counts().reset_index(name=\"Driver's_Gender_count\")\n",
    "a8 = a8.pivot_table(index='Policy_Number', columns=\"Driver's_Gender\",values=\"Driver's_Gender_count\",fill_value='0')\n",
    "\n",
    "# Driver's_Relationship_with_Insured\n",
    "a9 = dat2.groupby('Policy_Number',sort=False)[\"Driver's_Relationship_with_Insured\"].value_counts().reset_index(name=\"Driver's_Relationship_with_Insured_count\")\n",
    "a9 = a9.pivot_table(index='Policy_Number', columns=\"Driver's_Relationship_with_Insured\",values=\"Driver's_Relationship_with_Insured_count\",fill_value='0')\n",
    "\n",
    "# DOB_of_Driver\n",
    "a10 = df2.groupby('Policy_Number',sort=False)[\"DOB_of_Driver\"].mean().reset_index(name='DOB_of_Driver(mean)')\n",
    "\n",
    "# Accident_Date\n",
    "a11 = df2.groupby('Policy_Number',sort=False)[\"Accident_Date\"].mean().reset_index(name='Accident_Date(mean)')\n",
    "\n",
    "#Cause_of_Loss\n",
    "a12 = df2.groupby('Policy_Number',sort=False)[\"Cause_of_Loss\"].value_counts().reset_index(name=\"Cause_of_Loss_count\")\n",
    "a12 = a12.pivot_table(index='Policy_Number', columns=\"Cause_of_Loss\",values=\"Cause_of_Loss_count\",fill_value='0')\n",
    "\n",
    "# Accident_area\n",
    "a13 = df2.groupby('Policy_Number',sort=False)[\"Accident_area\"].value_counts().reset_index(name=\"Accident_area_count\")\n",
    "a13 = a13.pivot_table(index='Policy_Number', columns=\"Accident_area\",values=\"Accident_area_count\",fill_value='0')\n",
    "\n",
    "# number_of_claimants\n",
    "a14 = df2.groupby('Policy_Number',sort=False)[\"number_of_claimants\"].sum().reset_index(name=\"number_of_claimants(sum)\")\n",
    "a15 = df2.groupby('Policy_Number',sort=False)[\"number_of_claimants\"].mean().reset_index(name=\"number_of_claimants(mean)\")\n",
    "\n",
    "# Accident_Time\n",
    "a16 = df2.groupby('Policy_Number',sort=False)[\"Accident_Time\"].sum().reset_index(name=\"Accident_Time(sum)\")\n",
    "a17 = df2.groupby('Policy_Number',sort=False)[\"Accident_Time\"].mean().reset_index(name=\"Accident_Time(mean)\")\n",
    "\n",
    "# Paid_Loss_Amount\n",
    "a18 = dat2.groupby('Policy_Number',sort=False)[\"Paid_Loss_Amount\"].sum().reset_index(name=\"Paid_Loss_Amount(sum)\")\n",
    "\n",
    "# paid_Expenses_Amount\n",
    "a19 = dat2.groupby('Policy_Number',sort=False)[\"paid_Expenses_Amount\"].sum().reset_index(name=\"paid_Expenses_Amount(sum)\")\n",
    "\n",
    "# Salvage_or_Subrogation?\n",
    "a20 = dat2.groupby('Policy_Number',sort=False)[\"Salvage_or_Subrogation?\"].sum().reset_index(name=\"Salvage_or_Subrogation?(sum)\")\n",
    "\n",
    "# At_Fault\n",
    "a21 = df2.groupby('Policy_Number',sort=False)[\"At_Fault?\"].sum().reset_index(name=\"At_Fault?(sum)\") \n",
    "\n",
    "# Claim_Status_(close,_open,_reopen_etc)\n",
    "a22 = dat2.groupby('Policy_Number',sort=False)['Claim_Status_(close,_open,_reopen_etc)'].value_counts().reset_index(name='Claim_Status_count')\n",
    "a22 = a22.pivot_table(index='Policy_Number', columns='Claim_Status_(close,_open,_reopen_etc)', values='Claim_Status_count',fill_value = 0)\n",
    "\n",
    "# Deductible\n",
    "a23 = dat2.groupby('Policy_Number',sort=False)[\"Deductible\"].sum().reset_index(name=\"Deductible(sum)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "a8 = a8.astype('float')\n",
    "a9 = a9.astype('float')\n",
    "a12 = a12.astype('float')\n",
    "a13 = a13.astype('float')\n",
    "a6.columns = ['Nature_of_the_claim_1','Nature_of_the_claim_2' ]\n",
    "a7.columns = ['Marital_Status_of_Driver_1','Marital_Status_of_Driver_2' ]\n",
    "a8.columns = [\"Drivers_Gender_1\",\"Drivers_Gender_2\" ]\n",
    "a9.columns = [\"Drivers_Relationship_with_Insured_1\",\"Drivers_Relationship_with_Insured_2\",\"Drivers_Relationship_with_Insured_3\",\n",
    "             \"Drivers_Relationship_with_Insured_4\",\"Drivers_Relationship_with_Insured_5\",\"Drivers_Relationship_with_Insured_6\",\n",
    "             \"Drivers_Relationship_with_Insured_7\"]\n",
    "a12.columns = ['Cause_of_Loss_0','Cause_of_Loss_1','Cause_of_Loss_2','Cause_of_Loss_3','Cause_of_Loss_4','Cause_of_Loss_5',\n",
    "              'Cause_of_Loss_6','Cause_of_Loss_7','Cause_of_Loss_8','Cause_of_Loss_9','Cause_of_Loss_10','Cause_of_Loss_11',\n",
    "               'Cause_of_Loss_12','Cause_of_Loss_13','Cause_of_Loss_14','Cause_of_Loss_15','Cause_of_Loss_16']\n",
    "a13.columns = ['Accident_area_0','Accident_area_1','Accident_area_2','Accident_area_3','Accident_area_4','Accident_area_5',\n",
    "               'Accident_area_6','Accident_area_7','Accident_area_8','Accident_area_9','Accident_area_10','Accident_area_11',\n",
    "               'Accident_area_12','Accident_area_13','Accident_area_14','Accident_area_15','Accident_area_16',\n",
    "               'Accident_area_17','Accident_area_18','Accident_area_19','Accident_area_20','Accident_area_21']\n",
    "a22.columns = [\"Claim_Status__0\",\"Claim_Status__1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 合併資料\n",
    "\n",
    "dat = pd.merge(dat, a6, on=['Policy_Number'], how='left',sort=False).fillna(0)\n",
    "dat = pd.merge(dat, a7, on=['Policy_Number'], how='left',sort=False).fillna(0)\n",
    "dat = pd.merge(dat, a8, on=['Policy_Number'], how='left',sort=False).fillna(0)\n",
    "dat = pd.merge(dat, a9, on=['Policy_Number'], how='left',sort=False).fillna(0)\n",
    "dat = pd.merge(dat, a10, on=['Policy_Number'], how='left',sort=False).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dat = pd.merge(dat, a11, on=['Policy_Number'], how='left',sort=False)\n",
    "dat['ACC_Y_or_N'] = dat['Accident_Date(mean)'].isna()\n",
    "dat['Accident_Date(mean)'] = dat['Accident_Date(mean)'].fillna(2017)\n",
    "\n",
    "dat = pd.merge(dat, a12, on=['Policy_Number'], how='left',sort=False).fillna(0)\n",
    "dat = pd.merge(dat, a13, on=['Policy_Number'], how='left',sort=False).fillna(0)\n",
    "dat = pd.merge(dat, a14, on=['Policy_Number'], how='left',sort=False).fillna(0)\n",
    "dat = pd.merge(dat, a15, on=['Policy_Number'], how='left',sort=False).fillna(0)\n",
    "dat = pd.merge(dat, a16, on=['Policy_Number'], how='left',sort=False).fillna(0)\n",
    "dat = pd.merge(dat, a17, on=['Policy_Number'], how='left',sort=False).fillna(0)\n",
    "dat = pd.merge(dat, a18, on=['Policy_Number'], how='left',sort=False).fillna(0)\n",
    "dat = pd.merge(dat, a19, on=['Policy_Number'], how='left',sort=False).fillna(0)\n",
    "dat = pd.merge(dat, a20, on=['Policy_Number'], how='left',sort=False).fillna(0)\n",
    "dat = pd.merge(dat, a21, on=['Policy_Number'], how='left',sort=False).fillna(0)\n",
    "dat = pd.merge(dat, a22, on=['Policy_Number'], how='left',sort=False).fillna(0)\n",
    "dat = pd.merge(dat, a23, on=['Policy_Number'], how='left',sort=False).fillna(0)\n",
    "dat = pd.merge(dat,dat3, on=['Policy_Number'], how='left',sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat['iage'] = dat['Accident_Date(mean)'] - dat['ibirth']\n",
    "dat['dage'] = dat['Accident_Date(mean)'] - dat['dbirth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(351273, 226)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dat = dat.rename(columns={ ('Coverage_Deductible_if_applied', 0):'Coverage_Deductible_if_applied_0',\n",
    "                     ('Coverage_Deductible_if_applied', 1):'Coverage_Deductible_if_applied_1',\n",
    "                     ('Coverage_Deductible_if_applied', 2):'Coverage_Deductible_if_applied_2',\n",
    "                     ('Insured_Amount1', 0):'Insured_Amount1_0',('Insured_Amount1', 1):'Insured_Amount1_1',\n",
    "                     ('Insured_Amount1', 2):'Insured_Amount1_2',('Insured_Amount2', 0):'Insured_Amount2_0',\n",
    "                     ('Insured_Amount2', 1):'Insured_Amount2_1', ('Insured_Amount2', 2):'Insured_Amount2_2',\n",
    "                     ('Insured_Amount3', 0):'Insured_Amount3_0',\n",
    "                     ('Insured_Amount3', 1):'Insured_Amount3_1', ('Insured_Amount3', 2):'Insured_Amount3_2'  })\n",
    "\n",
    "dat.Cancellation = dat.Cancellation.astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing \n",
    "\n",
    "train = dat[dat['Next_Premium'].isna()==False]\n",
    "test = dat[dat['Next_Premium'].isna()==True]\n",
    "y = train['Next_Premium']\n",
    "features = [f for f in train.columns if f not in ['Next_Premium','Policy_Number']]\n",
    "\n",
    "data = train[features]\n",
    "pred = test[features]\n",
    "\n",
    "# Split train and validation set\n",
    "train_x, valid_x, train_y, valid_y = train_test_split(data, y, test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 標準化( X : scale , y : center)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdata = preprocessing.scale(data)\n",
    "spred = preprocessing.scale(pred)\n",
    "sy = train['Next_Premium'] - train['Next_Premium'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import cross_validation\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "model_1 = XGBRegressor(n_estimators=1000, learning_rate=0.05, gamma=0, subsample=1,\n",
    "         colsample_bytree=1, max_depth=10,eval_metric='mae')\n",
    "\n",
    "model_1.fit(sdata,sy) \n",
    "pred1 = model_1.predict(spred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result2 = pd.DataFrame()\n",
    "result2['Policy_Number'] = test.Policy_Number\n",
    "result2['Next_Premium'] = pred1\n",
    "result2['Next_Premium'] = result2['Next_Premium'] + train['Next_Premium'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test1 = pd.DataFrame()\n",
    "test1['Policy_Number'] = dat4['Policy_Number']\n",
    "submit = test1.merge(result2,on=['Policy_Number'])\n",
    "submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#submit.to_csv(\"submit(XGsc).csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 待編輯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xgb.fit(X=train_x,y=train_y,learning_rate=0.08, gamma=0,subsample=0.75,colsample_bytree=1, max_depth=7)\n",
    "\n",
    "#my_model1 = XGBRegressor(max_depth=7, learning_rate=0.08, n_estimators=300, silent=True, objective='reg:linear',\n",
    "#             booster='gbtree', n_jobs=1, nthread=None, gamma=0, min_child_weight=1, max_delta_step=0, \n",
    "#             subsample=0.75, colsample_bytree=1,seed=42)\n",
    "#my_model.fit(train_x, train_y)\n",
    "\n",
    "#for i in []:\n",
    "#    train_error = mean_absolute_error(my_model.predict(train_x), train_y)\n",
    "#    test_error  = mean_absolute_error(my_model.predict(valid_x), valid_y)\n",
    "#    print([train_error,test_error] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yifor\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#dtrain = xgb.DMatrix(train_x, label=train_y)\n",
    "#dtest = xgb.DMatrix(valid_x, label=valid_y)\n",
    "#Creating a function to determin the best fit n_estimators.\n",
    "#my_model = XGBRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning_rate=0.07  subsample=1  max_depth=8\n",
    "#def xgbr(n_estimator,X_train,X_test,y_train,y_test):\n",
    "#    my_model = XGBRegressor(n_estimators=n_estimator, learning_rate=0.07, gamma=0, \n",
    "#                            subsample=1,colsample_bytree=1, max_depth=8,silent=False)\n",
    "#    my_model.fit(X_train, y_train)\n",
    "#    pred = my_model.predict(X_test)\n",
    "#    return str(mean_absolute_error(pred, y_test))\n",
    "#\n",
    "#\n",
    "#for estimators in [1,50,100,200]:\n",
    "#    mae = xgbr(estimators,train_x,valid_x,train_y,valid_y)\n",
    "#    print(\"Number of estimators: {}  \\t\\t Mean Absolute Error:  {}\".format(estimators, mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_depth = 8 \n",
    "#def xgbr(n_estimator,X_train,X_test,y_train,y_test):\n",
    "#    my_model = XGBRegressor(n_estimators=n_estimator, learning_rate=0.08, gamma=0, \n",
    "#                            subsample=0.75,colsample_bytree=1, max_depth=8,silent=False)\n",
    "#    my_model.fit(X_train, y_train)\n",
    "#    pred = my_model.predict(X_test)\n",
    "#    return str(mean_absolute_error(pred, y_test))\n",
    "#\n",
    "#\n",
    "#for estimators in [1,50,100,200]:\n",
    "#    mae = xgbr(estimators,train_x,valid_x,train_y,valid_y)\n",
    "#    print(\"Number of estimators: {}  \\t\\t Mean Absolute Error:  {}\".format(estimators, mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning rate\n",
    "#def xgbr(n_estimator,X_train,X_test,y_train,y_test,max_depth1):\n",
    "#    my_model = XGBRegressor(n_estimators=n_estimator, learning_rate=0.05, gamma=0, \n",
    "#                            subsample=1,colsample_bytree=1, max_depth=max_depth1,silent=False)\n",
    "#    my_model.fit(X_train, y_train)\n",
    "#    pred = my_model.predict(X_test)\n",
    "#    return str(mean_absolute_error(pred, y_test))\n",
    "#\n",
    "#\n",
    "#for max_depth1 in [13,14,15,16]:\n",
    "#    mae = xgbr(200,train_x,valid_x,train_y,valid_y,max_depth1)\n",
    "#    print(\"Number of max_depth1: {}  \\t\\t Mean Absolute Error:  {}\".format(max_depth1, mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of max_depth1: 10  \t\t Mean Absolute Error:  1929.6098931936713\n",
    "#Number of max_depth1: 11  \t\t Mean Absolute Error:  1934.2185597545495\n",
    "#Number of max_depth1: 12  \t\t Mean Absolute Error:  1933.6417161912236"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build LightGBM Model\n",
    "\n",
    "#train_data=lgb.Dataset(train_x,label=train_y)\n",
    "#valid_data=lgb.Dataset(valid_x,label=valid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#param_={\n",
    "#'boosting_type': 'gbdt',\n",
    "#'class_weight': None,\n",
    "#'colsample_bytree': 0.733333,\n",
    "#'learning_rate': 0.00764107,\n",
    "#'max_depth': -1,\n",
    "#'min_child_samples': 460,\n",
    "#'min_child_weight': 0.001,\n",
    "#'min_split_gain': 0.0,\n",
    "#'n_estimators': 2673,\n",
    "#'n_jobs': -1,\n",
    "#'num_leaves': 77,\n",
    "#'objective': None,\n",
    "#'random_state': 42,\n",
    "#'reg_alpha': 0.877551,\n",
    "#'reg_lambda': 0.204082,\n",
    "#'silent': True,\n",
    "#'subsample': 0.949495,\n",
    "#'subsample_for_bin': 240000,\n",
    "#'subsample_freq': 1,\n",
    "#'metric': 'l1' # aliase for mae \n",
    "#}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train model on selected parameters and number of iterations\n",
    "#lgbm = lgb.train(param_,\n",
    "#train_data,\n",
    "#2500,\n",
    "#valid_sets=valid_data,\n",
    "#early_stopping_rounds= 40,\n",
    "#verbose_eval= 10\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# predict data\n",
    "\n",
    "#predictions_lgbm_prob =lgbm.predict(test)\n",
    "#result=pd.DataFrame()\n",
    "#result['Policy_Number']=df_test_1.Policy_Number[:-1]\n",
    "#result['Next_Premium']=predictions_lgbm_prob\n",
    "\n",
    "# combine next prenium by mean of same the policy\n",
    "\n",
    "#test1=df_test.copy()\n",
    "#result1=result.groupby(result['Policy_Number']).mean()\n",
    "#test1 = test1.merge(result1[['Next_Premium']], on=['Policy_Number'])\n",
    "#submit=test1[['Policy_Number','Next_Premium_y']]\n",
    "#submit=submit.rename(index=str, columns={\"Next_Premium_y\": \"Next_Premium\"})\n",
    "#submit.to_csv(\"submit1.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#lasso = LassoCV(alphas=[0.0001, 0.001, 0.006, 0.01, 0.03, 0.06, 0.1,0.3, 0.6, 1],max_iter=200, cv=5)\n",
    "#lasso.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_predicted = lasso.predict(X=valid_x)\n",
    "#\n",
    "#plt.figure(figsize=(10, 5))\n",
    "#plt.scatter(valid_y, y_predicted, s=20)\n",
    "#mae_pred_vs_actual = mean_absolute_error(y_predicted,valid_y)\n",
    "#\n",
    "#plt.title(''.join(['Predicted vs. Actual.', ' mae = ', str(mae_pred_vs_actual)]))\n",
    "#plt.xlabel('True')\n",
    "#plt.ylabel('Predicted')\n",
    "#plt.plot([min(valid_y), max(valid_y)], [min(valid_y), max(valid_y)])\n",
    "#plt.tight_layout() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
